{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvirshaikatx/Deep-Learning/blob/main/AS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHwHCpYLMXke"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_excel('/content/modified.xlsx')"
      ],
      "metadata": {
        "id": "hMEtpbpePjll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GHjsESLLPmEC",
        "outputId": "97b0b713-fce7-4afc-b4b6-69e1bcaadb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    d1(um)  d2(um)  d3(um)  tg(um)  pitch(um)  wl(um)    na  \\\n",
              "0      1.6     0.8     0.4    0.04          2   0.475  1.21   \n",
              "1      1.6     0.8     0.4    0.04          2   0.480  1.21   \n",
              "2      1.6     0.8     0.4    0.04          2   0.485  1.21   \n",
              "3      1.6     0.8     0.4    0.04          2   0.490  1.21   \n",
              "4      1.6     0.8     0.4    0.04          2   0.495  1.21   \n",
              "..     ...     ...     ...     ...        ...     ...   ...   \n",
              "69     1.6     0.8     0.4    0.04          2   0.820  1.21   \n",
              "70     1.6     0.8     0.4    0.04          2   0.825  1.21   \n",
              "71     1.6     0.8     0.4    0.04          2   0.830  1.21   \n",
              "72     1.6     0.8     0.4    0.04          2   0.835  1.21   \n",
              "73     1.6     0.8     0.4    0.04          2   0.840  1.21   \n",
              "\n",
              "    neff y core(real)  confinement loss (dB/cm)  amplitude sensitivity   \n",
              "0            1.462259                 10.111846               -0.224618  \n",
              "1            1.461911                  9.920842               -0.306415  \n",
              "2            1.461571                  9.565779               -0.184299  \n",
              "3            1.461241                  9.086011                0.103128  \n",
              "4            1.460919                  8.521663                0.439691  \n",
              "..                ...                       ...                     ...  \n",
              "69           1.448436                  4.414345                0.011215  \n",
              "70           1.448300                  4.544164                0.063916  \n",
              "71           1.448163                  4.682469                0.087721  \n",
              "72           1.448028                  4.820449                0.073945  \n",
              "73           1.447893                  4.959263                0.111146  \n",
              "\n",
              "[74 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa4c7cfd-ca69-4827-9eea-1b346cab27c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d1(um)</th>\n",
              "      <th>d2(um)</th>\n",
              "      <th>d3(um)</th>\n",
              "      <th>tg(um)</th>\n",
              "      <th>pitch(um)</th>\n",
              "      <th>wl(um)</th>\n",
              "      <th>na</th>\n",
              "      <th>neff y core(real)</th>\n",
              "      <th>confinement loss (dB/cm)</th>\n",
              "      <th>amplitude sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.475</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.462259</td>\n",
              "      <td>10.111846</td>\n",
              "      <td>-0.224618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.480</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461911</td>\n",
              "      <td>9.920842</td>\n",
              "      <td>-0.306415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.485</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461571</td>\n",
              "      <td>9.565779</td>\n",
              "      <td>-0.184299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.490</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461241</td>\n",
              "      <td>9.086011</td>\n",
              "      <td>0.103128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.495</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.460919</td>\n",
              "      <td>8.521663</td>\n",
              "      <td>0.439691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.820</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.448436</td>\n",
              "      <td>4.414345</td>\n",
              "      <td>0.011215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.825</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.448300</td>\n",
              "      <td>4.544164</td>\n",
              "      <td>0.063916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.830</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.448163</td>\n",
              "      <td>4.682469</td>\n",
              "      <td>0.087721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.835</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.448028</td>\n",
              "      <td>4.820449</td>\n",
              "      <td>0.073945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.840</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.447893</td>\n",
              "      <td>4.959263</td>\n",
              "      <td>0.111146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa4c7cfd-ca69-4827-9eea-1b346cab27c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa4c7cfd-ca69-4827-9eea-1b346cab27c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa4c7cfd-ca69-4827-9eea-1b346cab27c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f022acd6-102f-4582-b913-c6a78b1fa54c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f022acd6-102f-4582-b913-c6a78b1fa54c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f022acd6-102f-4582-b913-c6a78b1fa54c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e78f7c2-8f84-4368-9d51-a5991dfbc010\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e78f7c2-8f84-4368-9d51-a5991dfbc010 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74,\n  \"fields\": [\n    {\n      \"column\": \"d1(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.471205707052524e-16,\n        \"min\": 1.6,\n        \"max\": 1.6,\n        \"samples\": [\n          1.6\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d2(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.235602853526262e-16,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"samples\": [\n          0.8\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d3(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.117801426763131e-16,\n        \"min\": 0.4,\n        \"max\": 0.4,\n        \"samples\": [\n          0.4\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tg(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.04,\n        \"max\": 0.04,\n        \"samples\": [\n          0.04\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pitch(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"samples\": [\n          2\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wl(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10752906583803283,\n        \"min\": 0.475,\n        \"max\": 0.84,\n        \"samples\": [\n          0.495\n        ],\n        \"num_unique_values\": 74,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"na\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.21,\n        \"max\": 1.21,\n        \"samples\": [\n          1.21\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neff y core(real)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004084699392423996,\n        \"min\": 1.447892551,\n        \"max\": 1.46225925,\n        \"samples\": [\n          1.460918504\n        ],\n        \"num_unique_values\": 74,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confinement loss (dB/cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9031760102022042,\n        \"min\": 2.437583258,\n        \"max\": 10.11184577,\n        \"samples\": [\n          8.521663173\n        ],\n        \"num_unique_values\": 74,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amplitude sensitivity \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.073731036861331,\n        \"min\": -20.86340214,\n        \"max\": 0.939690138,\n        \"samples\": [\n          0.439691487\n        ],\n        \"num_unique_values\": 74,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel('modified.xlsx', sheet_name='na=1.21')\n",
        "df2 = pd.read_excel('modified.xlsx', sheet_name='na=1.22')\n",
        "df3 = pd.read_excel('modified.xlsx', sheet_name='na=1.23')\n",
        "df4 = pd.read_excel('modified.xlsx', sheet_name='na=1.24')\n",
        "df5 = pd.read_excel('modified.xlsx', sheet_name='na=1.25')\n",
        "df6 = pd.read_excel('modified.xlsx', sheet_name='na=1.26')\n",
        "df7 = pd.read_excel('modified.xlsx', sheet_name='na=1.27')\n",
        "df8 = pd.read_excel('modified.xlsx', sheet_name='na=1.28')\n",
        "df9 = pd.read_excel('modified.xlsx', sheet_name='na=1.29')\n",
        "df10 = pd.read_excel('modified.xlsx', sheet_name='na=1.30')\n",
        "df11 = pd.read_excel('modified.xlsx', sheet_name='na=1.31')\n",
        "df12 = pd.read_excel('modified.xlsx', sheet_name='na=1.32')\n",
        "df13 = pd.read_excel('modified.xlsx', sheet_name='na=1.33')\n",
        "df14 = pd.read_excel('modified.xlsx', sheet_name='na=1.34')\n",
        "df15 = pd.read_excel('modified.xlsx', sheet_name='na=1.35')\n",
        "df16 = pd.read_excel('modified.xlsx', sheet_name='na=1.36')\n",
        "df17 = pd.read_excel('modified.xlsx', sheet_name='na=1.37')\n",
        "df18 = pd.read_excel('modified.xlsx', sheet_name='na=1.38')\n",
        "df19 = pd.read_excel('modified.xlsx', sheet_name='na=1.39')\n",
        "df20 = pd.read_excel('modified.xlsx', sheet_name='na=1.40')\n",
        "df21 = pd.read_excel('modified.xlsx', sheet_name='na=1.41')\n",
        "df22 = pd.read_excel('modified.xlsx', sheet_name='na=1.42')\n",
        "df23 = pd.read_excel('modified.xlsx', sheet_name='na=1.43')\n",
        "df24 = pd.read_excel('modified.xlsx', sheet_name='na=1.44')\n",
        "df25 = pd.read_excel('modified.xlsx', sheet_name='na=1.45')\n",
        "df26 = pd.read_excel('modified.xlsx', sheet_name='na=1.46')\n",
        "df27 = pd.read_excel('modified.xlsx', sheet_name='na=1.47')\n",
        "df28 = pd.read_excel('modified.xlsx', sheet_name='na=1.48')"
      ],
      "metadata": {
        "id": "lQWBOUtEPoO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df18, df19, df20, df21, df22, df23, df24, df25, df26, df27, df28])"
      ],
      "metadata": {
        "id": "ICDf0a-ZPrHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LkGH17-uPs3Z",
        "outputId": "13a40dbb-3769-4f26-d75e-904aa88667a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    d1(um)  d2(um)  d3(um)  tg(um)  pitch(um)  wl(um)    na  \\\n",
              "0      1.6     0.8     0.4    0.04          2   0.475  1.21   \n",
              "1      1.6     0.8     0.4    0.04          2   0.480  1.21   \n",
              "2      1.6     0.8     0.4    0.04          2   0.485  1.21   \n",
              "3      1.6     0.8     0.4    0.04          2   0.490  1.21   \n",
              "4      1.6     0.8     0.4    0.04          2   0.495  1.21   \n",
              "..     ...     ...     ...     ...        ...     ...   ...   \n",
              "69     1.6     0.8     0.4    0.04          2   0.820  1.48   \n",
              "70     1.6     0.8     0.4    0.04          2   0.825  1.48   \n",
              "71     1.6     0.8     0.4    0.04          2   0.830  1.48   \n",
              "72     1.6     0.8     0.4    0.04          2   0.835  1.48   \n",
              "73     1.6     0.8     0.4    0.04          2   0.840  1.48   \n",
              "\n",
              "    neff y core(real)  confinement loss (dB/cm)  amplitude sensitivity   \n",
              "0            1.462259                 10.111846               -0.224618  \n",
              "1            1.461911                  9.920842               -0.306415  \n",
              "2            1.461571                  9.565779               -0.184299  \n",
              "3            1.461241                  9.086011                0.103128  \n",
              "4            1.460919                  8.521663                0.439691  \n",
              "..                ...                       ...                     ...  \n",
              "69           1.448435                  4.550772                5.743918  \n",
              "70           1.448299                  4.688233                5.609120  \n",
              "71           1.448162                  4.824704                4.886012  \n",
              "72           1.448027                  4.962715                6.386163  \n",
              "73           1.447891                  5.117693               10.483188  \n",
              "\n",
              "[2072 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91c46634-a8ee-4ba9-b149-96cf40e15b40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d1(um)</th>\n",
              "      <th>d2(um)</th>\n",
              "      <th>d3(um)</th>\n",
              "      <th>tg(um)</th>\n",
              "      <th>pitch(um)</th>\n",
              "      <th>wl(um)</th>\n",
              "      <th>na</th>\n",
              "      <th>neff y core(real)</th>\n",
              "      <th>confinement loss (dB/cm)</th>\n",
              "      <th>amplitude sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.475</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.462259</td>\n",
              "      <td>10.111846</td>\n",
              "      <td>-0.224618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.480</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461911</td>\n",
              "      <td>9.920842</td>\n",
              "      <td>-0.306415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.485</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461571</td>\n",
              "      <td>9.565779</td>\n",
              "      <td>-0.184299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.490</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.461241</td>\n",
              "      <td>9.086011</td>\n",
              "      <td>0.103128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.495</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.460919</td>\n",
              "      <td>8.521663</td>\n",
              "      <td>0.439691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.820</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.448435</td>\n",
              "      <td>4.550772</td>\n",
              "      <td>5.743918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.825</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.448299</td>\n",
              "      <td>4.688233</td>\n",
              "      <td>5.609120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.830</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.448162</td>\n",
              "      <td>4.824704</td>\n",
              "      <td>4.886012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.835</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.448027</td>\n",
              "      <td>4.962715</td>\n",
              "      <td>6.386163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>0.840</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.447891</td>\n",
              "      <td>5.117693</td>\n",
              "      <td>10.483188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2072 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91c46634-a8ee-4ba9-b149-96cf40e15b40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91c46634-a8ee-4ba9-b149-96cf40e15b40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91c46634-a8ee-4ba9-b149-96cf40e15b40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b08a0d9c-6dfa-4ee2-9391-7f8e1d279f5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b08a0d9c-6dfa-4ee2-9391-7f8e1d279f5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b08a0d9c-6dfa-4ee2-9391-7f8e1d279f5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9b7f971f-d886-4e7e-8d53-a7c1a1f34182\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9b7f971f-d886-4e7e-8d53-a7c1a1f34182 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 2072,\n  \"fields\": [\n    {\n      \"column\": \"d1(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.6,\n        \"max\": 1.6,\n        \"samples\": [\n          1.6\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d2(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"samples\": [\n          0.8\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d3(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.4,\n        \"max\": 0.4,\n        \"samples\": [\n          0.4\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tg(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.04,\n        \"max\": 0.04,\n        \"samples\": [\n          0.04\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pitch(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"samples\": [\n          2\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wl(um)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10682582836103696,\n        \"min\": 0.475,\n        \"max\": 0.84,\n        \"samples\": [\n          0.495\n        ],\n        \"num_unique_values\": 74,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"na\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08079697179881806,\n        \"min\": 1.21,\n        \"max\": 1.48,\n        \"samples\": [\n          1.3\n        ],\n        \"num_unique_values\": 28,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neff y core(real)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004063373384985026,\n        \"min\": 1.446604042,\n        \"max\": 1.462259257,\n        \"samples\": [\n          1.454013557\n        ],\n        \"num_unique_values\": 1988,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confinement loss (dB/cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1069691531418853,\n        \"min\": 2.437583258,\n        \"max\": 14.42263583,\n        \"samples\": [\n          3.04273272\n        ],\n        \"num_unique_values\": 2072,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amplitude sensitivity \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 865.0616835764845,\n        \"min\": -5099.114358,\n        \"max\": 7912.923732,\n        \"samples\": [\n          -1.58384981\n        ],\n        \"num_unique_values\": 1998,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5zFZpYEPvFc",
        "outputId": "9c6d4681-a10a-448b-fdb6-df8c9fe4e6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxY2JOktPw-_",
        "outputId": "d5f79af3-862f-4d7a-abc9-f98bc4d3cefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['d1(um)', 'd2(um)', 'd3(um)', 'tg(um)', 'pitch(um)', 'wl(um)', 'na',\n",
              "       'neff y core(real)', 'confinement loss (dB/cm)',\n",
              "       'amplitude sensitivity '],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excel_file_path = '/content/modified.xlsx'\n",
        "# Save the combined DataFrame to Excel\n",
        "combined_df.to_excel(excel_file_path, index=False)"
      ],
      "metadata": {
        "id": "4SAQ02rwPyee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features and target variables\n",
        "x_cols = ['d1(um)', 'd2(um)', 'd3(um)', 'tg(um)', 'pitch(um)', 'na','wl(um)', 'neff y core(real)']\n",
        "y_cols = ['amplitude sensitivity ']\n",
        "\n",
        "x = combined_df[x_cols]\n",
        "y = combined_df[y_cols]"
      ],
      "metadata": {
        "id": "TZTwKeFXP3T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x.values)\n",
        "y_scaled = scaler.fit_transform(y.values)"
      ],
      "metadata": {
        "id": "yZvpyJhnP9eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Step 2: Split the data\n",
        "X_train_scaled, X_test_scaled, Y_train_scaled, Y_test_scaled = train_test_split(x_scaled, y_scaled , test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Choose a model (Random Forest Regressor for regression tasks)\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Step 4: Use MultiOutputRegressor to handle multiple outputs\n",
        "multi_output_model = MultiOutputRegressor(model)\n",
        "\n",
        "# Step 5: Train the model\n",
        "multi_output_model.fit(X_train_scaled, Y_train_scaled)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "Y_pred = multi_output_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(Y_test_scaled, Y_pred)\n",
        "print(\"Mean Squared Error for RFR:\", mse)\n",
        "# Assuming y_test_scaled and y_pred are your scaled actual and predicted labels, respectively\n",
        "r2 = r2_score(Y_test_scaled, Y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate accuracy for each target variable separately\n",
        "for i in range(len(y_cols)):\n",
        "    mse = mean_squared_error(Y_test_scaled[:, i], Y_pred[:, i])  # Calculate MSE for each target\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE\n",
        "    accuracy = 1 - rmse / np.mean(Y_test_scaled[:, i])  # Calculate accuracy as 1 - normalized RMSE\n",
        "    print(f\"Accuracy for {y_cols[i]}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI9fomMrQE5a",
        "outputId": "45bac263-dc36-4152-fd79-5141f57d3579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for RFR: 0.00022276404586136597\n",
            "R-squared: 0.9445908955298328\n",
            "Accuracy for amplitude sensitivity : 0.9628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "# Step 3: Choose a model (Gradient Boosting Regressor for regression tasks)\n",
        "model = GradientBoostingRegressor()\n",
        "\n",
        "# Step 4: Use MultiOutputRegressor to handle multiple outputs\n",
        "multi_output_model = MultiOutputRegressor(model)\n",
        "\n",
        "# Step 5: Train the model\n",
        "multi_output_model.fit(X_train_scaled, Y_train_scaled)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "y_pred = multi_output_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(Y_test_scaled, y_pred)\n",
        "print(\"Mean Squared Error for GBR:\", mse)\n",
        "# Assuming y_test_scaled and y_pred are your scaled actual and predicted labels, respectively\n",
        "r2 = r2_score(Y_test_scaled, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate accuracy for each target variable separately\n",
        "for i in range(len(y_cols)):\n",
        "    mse = mean_squared_error(Y_test_scaled[:, i], y_pred[:, i])  # Calculate MSE for each target\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE\n",
        "    accuracy = 1 - rmse / np.mean(Y_test_scaled[:, i])  # Calculate accuracy as 1 - normalized RMSE\n",
        "    print(f\"Accuracy for {y_cols[i]}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKs0_ywXQu6Y",
        "outputId": "6a30cf6d-0663-45dd-8895-2db9ecf3f231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for GBR: 0.0010436738022460558\n",
            "R-squared: 0.7404023143958454\n",
            "Accuracy for amplitude sensitivity : 0.9194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "# Step 3: Choose a model (Decision Tree Regressor for regression tasks)\n",
        "model = DecisionTreeRegressor()\n",
        "\n",
        "# Step 4: Use MultiOutputRegressor to handle multiple outputs\n",
        "multi_output_model = MultiOutputRegressor(model)\n",
        "\n",
        "# Step 5: Train the model\n",
        "multi_output_model.fit(X_train_scaled, Y_train_scaled)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "Y_pred = multi_output_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(Y_test_scaled, Y_pred)\n",
        "print(\"Mean Squared Error for Decision Tree:\", mse)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(Y_test_scaled, Y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate accuracy for each target variable separately\n",
        "for i in range(len(y_cols)):\n",
        "    mse = mean_squared_error(Y_test_scaled[:, i], Y_pred[:, i])  # Calculate MSE for each target\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE\n",
        "    accuracy = 1 - rmse / np.mean(Y_test_scaled[:, i])  # Calculate accuracy as 1 - normalized RMSE\n",
        "    print(f\"Accuracy for {y_cols[i]}: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJUxKqE6TcTC",
        "outputId": "42b00d0f-9884-449b-ed9a-724185f31a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for Decision Tree: 0.0015838294534816742\n",
            "R-squared: 0.6060469663694774\n",
            "Accuracy for amplitude sensitivity : 0.9007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "# Step 3: Choose a model (Support Vector Machine Regressor for regression tasks)\n",
        "model = SVR()\n",
        "\n",
        "# Step 4: Use MultiOutputRegressor to handle multiple outputs\n",
        "multi_output_model = MultiOutputRegressor(model)\n",
        "\n",
        "# Step 5: Train the model\n",
        "multi_output_model.fit(X_train_scaled, Y_train_scaled)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "Y_pred = multi_output_model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(Y_test_scaled, Y_pred)\n",
        "print(\"Mean Squared Error for Support Vector Machine:\", mse)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(Y_test_scaled, Y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate accuracy for each target variable separately\n",
        "for i in range(len(y_cols)):\n",
        "    mse = mean_squared_error(Y_test_scaled[:, i], Y_pred[:, i])  # Calculate MSE for each target\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE\n",
        "    accuracy = 1 - rmse / np.mean(Y_test_scaled[:, i])  # Calculate accuracy as 1 - normalized RMSE\n",
        "    print(f\"Accuracy for {y_cols[i]}: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHjzKrv0UYSf",
        "outputId": "47724aee-cf78-4698-e56e-db0c5dbf4ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for Support Vector Machine: 0.007283523016589957\n",
            "R-squared: -0.8116634853555267\n",
            "Accuracy for amplitude sensitivity : 0.7871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled, Y_train_scaled, Y_test_scaled = train_test_split(x_scaled, y_scaled , test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "VAXFvgldRcPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmOKynf6eaDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(Y_train_scaled.shape[1])  # Output layer with the same number of units as target variables\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, Y_train_scaled, epochs=500, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "Y_pred_scaled = model.predict(X_test_scaled)\n",
        "\n",
        "# Inverse transform the predictions to the original scale\n",
        "# y_pred = scaler_Y.inverse_transform(Y_pred_scaled)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(Y_test_scaled, Y_pred_scaled)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sNN0pozmRdEL",
        "outputId": "f0acfe22-aacc-478e-9f37-85e889a15b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "42/42 [==============================] - 1s 6ms/step - loss: 0.0377 - accuracy: 7.5472e-04 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 7.5472e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/500\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 7.5472e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 7.5472e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 7.5472e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 7.5472e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 7.5472e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.0015 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 7.5472e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 7.5472e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 7.5472e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.0015 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.0015 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 7.5472e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 7.5472e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 7.5472e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.0015 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 7.5472e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.0015 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.0015 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.0015 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 7.5472e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 7.5472e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0015 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.0015 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.0015 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.0015 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 7.5472e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.0015 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 7.5472e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.0015 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.0015 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.0015 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0015 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 7.5472e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0015 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0015 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0015 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 8.6812e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 8.5398e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0015 - val_loss: 8.4457e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 7.1416e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 5.7135e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.4068e-04 - accuracy: 0.0015 - val_loss: 9.6397e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0015 - val_loss: 5.8646e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 6.7168e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9562e-04 - accuracy: 0.0015 - val_loss: 5.6599e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.7792e-04 - accuracy: 0.0015 - val_loss: 7.6060e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.3978e-04 - accuracy: 0.0015 - val_loss: 8.3988e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.4245e-04 - accuracy: 0.0015 - val_loss: 6.5439e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 7.5472e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.4591e-04 - accuracy: 0.0015 - val_loss: 3.9577e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4008e-04 - accuracy: 0.0015 - val_loss: 5.2285e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.7480e-04 - accuracy: 0.0015 - val_loss: 3.9458e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7511e-04 - accuracy: 0.0015 - val_loss: 6.2812e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7842e-04 - accuracy: 0.0015 - val_loss: 7.5717e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.3240e-04 - accuracy: 0.0015 - val_loss: 2.8431e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8033e-04 - accuracy: 0.0015 - val_loss: 3.3226e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.1637e-04 - accuracy: 0.0015 - val_loss: 5.1554e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3635e-04 - accuracy: 0.0015 - val_loss: 2.6611e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3234e-04 - accuracy: 0.0015 - val_loss: 3.0826e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.1229e-04 - accuracy: 0.0015 - val_loss: 2.3511e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3788e-04 - accuracy: 0.0015 - val_loss: 8.2280e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.5084e-04 - accuracy: 0.0015 - val_loss: 4.3930e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7533e-04 - accuracy: 0.0015 - val_loss: 2.7542e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9594e-04 - accuracy: 0.0015 - val_loss: 8.3028e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9851e-04 - accuracy: 0.0015 - val_loss: 2.8662e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0015 - val_loss: 9.5265e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 3.0745e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.2466e-04 - accuracy: 0.0015 - val_loss: 1.1275e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4096e-04 - accuracy: 0.0015 - val_loss: 1.6977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0648e-04 - accuracy: 0.0015 - val_loss: 9.5978e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5760e-04 - accuracy: 0.0015 - val_loss: 1.0668e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4474e-04 - accuracy: 0.0015 - val_loss: 1.9737e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8004e-04 - accuracy: 0.0015 - val_loss: 1.0158e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7350e-04 - accuracy: 0.0015 - val_loss: 1.1914e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5556e-04 - accuracy: 0.0015 - val_loss: 1.0542e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6400e-04 - accuracy: 0.0015 - val_loss: 1.0537e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8315e-04 - accuracy: 0.0015 - val_loss: 2.0588e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4853e-04 - accuracy: 0.0015 - val_loss: 2.9599e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3061e-04 - accuracy: 0.0015 - val_loss: 2.3986e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6171e-04 - accuracy: 0.0015 - val_loss: 2.1752e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1688e-04 - accuracy: 0.0015 - val_loss: 1.3054e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4216e-04 - accuracy: 0.0015 - val_loss: 1.6269e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.1104e-04 - accuracy: 0.0015 - val_loss: 1.9084e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1861e-04 - accuracy: 0.0015 - val_loss: 1.6742e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2929e-04 - accuracy: 0.0015 - val_loss: 1.6102e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1455e-04 - accuracy: 0.0015 - val_loss: 3.4031e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.9167e-04 - accuracy: 0.0015 - val_loss: 9.3648e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 3.4889e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7410e-04 - accuracy: 0.0015 - val_loss: 1.6731e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4759e-04 - accuracy: 0.0015 - val_loss: 2.4467e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6463e-04 - accuracy: 0.0015 - val_loss: 8.9799e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6245e-04 - accuracy: 0.0015 - val_loss: 1.6295e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.8215e-04 - accuracy: 0.0015 - val_loss: 1.9112e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5954e-04 - accuracy: 0.0015 - val_loss: 3.9227e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 2.4824e-04 - accuracy: 0.0015 - val_loss: 6.8398e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 1.0927e-04 - accuracy: 0.0015 - val_loss: 1.5798e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.1162e-04 - accuracy: 0.0015 - val_loss: 1.7392e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.4338e-04 - accuracy: 0.0015 - val_loss: 7.2774e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 7.7966e-05 - accuracy: 0.0015 - val_loss: 7.1652e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.3628e-04 - accuracy: 0.0015 - val_loss: 2.6765e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.6044e-04 - accuracy: 0.0015 - val_loss: 3.8283e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 6.2195e-04 - accuracy: 0.0015 - val_loss: 4.4857e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 2.2411e-04 - accuracy: 0.0015 - val_loss: 6.2902e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.0936e-04 - accuracy: 0.0015 - val_loss: 1.1124e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 9.7766e-05 - accuracy: 0.0015 - val_loss: 1.3483e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 8.1010e-05 - accuracy: 0.0015 - val_loss: 1.0587e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4058e-04 - accuracy: 0.0015 - val_loss: 2.8030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1903e-04 - accuracy: 0.0015 - val_loss: 1.1299e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2849e-04 - accuracy: 0.0015 - val_loss: 5.0298e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7841e-04 - accuracy: 0.0015 - val_loss: 1.9068e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.1298e-04 - accuracy: 0.0015 - val_loss: 1.4880e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8014e-04 - accuracy: 0.0015 - val_loss: 1.2664e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.0197e-05 - accuracy: 0.0015 - val_loss: 9.4406e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6108e-04 - accuracy: 0.0015 - val_loss: 9.2313e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8927e-04 - accuracy: 0.0015 - val_loss: 2.4752e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5935e-04 - accuracy: 0.0015 - val_loss: 2.2317e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2228e-04 - accuracy: 0.0015 - val_loss: 1.0530e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.2641e-05 - accuracy: 0.0015 - val_loss: 5.2677e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0471e-04 - accuracy: 0.0015 - val_loss: 1.3930e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.0015 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0015 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0015 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0015 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0015 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 7.5472e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 8.6648e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 8.1161e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 9.1966e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 7.9320e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 7.0113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 7.7281e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0015 - val_loss: 8.5376e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0015 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 9.3284e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 7.6772e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0015 - val_loss: 9.8100e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.8069e-04 - accuracy: 0.0015 - val_loss: 8.5480e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 4.7117e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.2098e-04 - accuracy: 0.0015 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.6822e-04 - accuracy: 0.0015 - val_loss: 9.7323e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 8.5213e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.1458e-04 - accuracy: 0.0015 - val_loss: 5.3646e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.2382e-04 - accuracy: 0.0015 - val_loss: 4.1473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.5154e-04 - accuracy: 0.0015 - val_loss: 4.9318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0265e-04 - accuracy: 0.0015 - val_loss: 7.1622e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 5.6324e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8220e-04 - accuracy: 0.0015 - val_loss: 3.3124e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5288e-04 - accuracy: 0.0015 - val_loss: 2.4504e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.5006e-04 - accuracy: 0.0015 - val_loss: 2.3229e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4532e-04 - accuracy: 0.0015 - val_loss: 5.9147e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7783e-04 - accuracy: 0.0015 - val_loss: 3.5526e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5090e-04 - accuracy: 0.0015 - val_loss: 5.6448e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.6472e-04 - accuracy: 0.0015 - val_loss: 5.2937e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.8155e-04 - accuracy: 0.0015 - val_loss: 2.5896e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3829e-04 - accuracy: 0.0015 - val_loss: 1.9573e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3754e-04 - accuracy: 0.0015 - val_loss: 2.8532e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7662e-04 - accuracy: 0.0015 - val_loss: 4.4896e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1471e-04 - accuracy: 0.0015 - val_loss: 5.2224e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.2954e-04 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.4665e-04 - accuracy: 0.0015 - val_loss: 8.0597e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9876e-04 - accuracy: 0.0015 - val_loss: 2.2561e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9374e-04 - accuracy: 0.0015 - val_loss: 2.3385e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7651e-04 - accuracy: 0.0015 - val_loss: 2.8687e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 3.6493e-04 - accuracy: 0.0015 - val_loss: 1.9171e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 2.9846e-04 - accuracy: 0.0015 - val_loss: 6.8695e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 5.6777e-04 - accuracy: 0.0015 - val_loss: 2.9981e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.1138e-04 - accuracy: 0.0015 - val_loss: 2.9867e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.5223e-04 - accuracy: 0.0015 - val_loss: 2.6222e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 6.5468e-04 - accuracy: 0.0015 - val_loss: 3.1376e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 6.0932e-04 - accuracy: 0.0015 - val_loss: 3.1643e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 3.1160e-04 - accuracy: 0.0015 - val_loss: 5.3331e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 5.5716e-04 - accuracy: 0.0015 - val_loss: 7.6229e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 4.4085e-04 - accuracy: 0.0015 - val_loss: 5.3032e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 5.5300e-04 - accuracy: 0.0015 - val_loss: 2.7918e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 2.7447e-04 - accuracy: 0.0015 - val_loss: 2.7786e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 6.9316e-04 - accuracy: 0.0015 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0015 - val_loss: 3.4481e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3741e-04 - accuracy: 0.0015 - val_loss: 2.0649e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7274e-04 - accuracy: 0.0015 - val_loss: 1.6896e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.4894e-04 - accuracy: 0.0015 - val_loss: 5.2887e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.8486e-04 - accuracy: 0.0015 - val_loss: 2.8576e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7928e-04 - accuracy: 0.0015 - val_loss: 2.5293e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2358e-04 - accuracy: 0.0015 - val_loss: 9.6888e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3917e-04 - accuracy: 0.0015 - val_loss: 2.2261e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.0720e-04 - accuracy: 0.0015 - val_loss: 2.0741e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6419e-04 - accuracy: 0.0015 - val_loss: 1.8659e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1822e-04 - accuracy: 0.0015 - val_loss: 1.1777e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6067e-04 - accuracy: 0.0015 - val_loss: 2.4291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6657e-04 - accuracy: 0.0015 - val_loss: 1.7291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4704e-04 - accuracy: 0.0015 - val_loss: 2.2442e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7819e-04 - accuracy: 0.0015 - val_loss: 2.0316e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7333e-04 - accuracy: 0.0015 - val_loss: 1.6358e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2318e-04 - accuracy: 0.0015 - val_loss: 1.4987e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6034e-04 - accuracy: 0.0015 - val_loss: 1.9812e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5350e-04 - accuracy: 0.0015 - val_loss: 8.6835e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9086e-04 - accuracy: 0.0015 - val_loss: 6.5758e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 8.5626e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.6886e-04 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.8503e-04 - accuracy: 0.0015 - val_loss: 1.2701e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.4816e-04 - accuracy: 0.0015 - val_loss: 3.3056e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8529e-04 - accuracy: 0.0015 - val_loss: 3.5131e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7073e-04 - accuracy: 0.0015 - val_loss: 7.5342e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1345e-04 - accuracy: 0.0015 - val_loss: 2.6662e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0610e-04 - accuracy: 0.0015 - val_loss: 2.5936e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8689e-04 - accuracy: 0.0015 - val_loss: 1.1789e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4979e-04 - accuracy: 0.0015 - val_loss: 2.1399e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7928e-04 - accuracy: 0.0015 - val_loss: 1.1766e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2110e-04 - accuracy: 0.0015 - val_loss: 8.6649e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2762e-04 - accuracy: 0.0015 - val_loss: 1.4430e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4058e-04 - accuracy: 0.0015 - val_loss: 9.7127e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2549e-04 - accuracy: 0.0015 - val_loss: 9.3816e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.9630e-05 - accuracy: 0.0015 - val_loss: 6.6245e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0206e-04 - accuracy: 0.0015 - val_loss: 1.4181e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0618e-04 - accuracy: 0.0015 - val_loss: 1.2279e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.5821e-05 - accuracy: 0.0015 - val_loss: 9.3717e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.8783e-05 - accuracy: 0.0015 - val_loss: 6.9909e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.8687e-05 - accuracy: 0.0015 - val_loss: 6.5684e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.4548e-05 - accuracy: 0.0015 - val_loss: 9.0580e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.5203e-05 - accuracy: 0.0015 - val_loss: 1.0908e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.8201e-05 - accuracy: 0.0015 - val_loss: 1.0385e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.5057e-04 - accuracy: 0.0015 - val_loss: 2.2401e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3720e-04 - accuracy: 0.0015 - val_loss: 2.7353e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.6087e-04 - accuracy: 0.0015 - val_loss: 2.3913e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3647e-04 - accuracy: 0.0015 - val_loss: 1.0597e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0901e-04 - accuracy: 0.0015 - val_loss: 8.0176e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.2805e-05 - accuracy: 0.0015 - val_loss: 1.4417e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6342e-04 - accuracy: 0.0015 - val_loss: 8.2479e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.8445e-05 - accuracy: 0.0015 - val_loss: 1.1264e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0447e-04 - accuracy: 0.0015 - val_loss: 5.1031e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.1214e-05 - accuracy: 0.0015 - val_loss: 7.1811e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5338e-04 - accuracy: 0.0015 - val_loss: 1.4649e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.0026e-04 - accuracy: 0.0015 - val_loss: 9.7906e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9911e-04 - accuracy: 0.0015 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0015 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 4.8458e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.9194e-04 - accuracy: 0.0015 - val_loss: 2.3199e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0376e-04 - accuracy: 0.0015 - val_loss: 7.0625e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.3633e-04 - accuracy: 0.0015 - val_loss: 1.6844e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5867e-04 - accuracy: 0.0015 - val_loss: 7.6312e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.6234e-05 - accuracy: 0.0015 - val_loss: 1.7064e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0919e-04 - accuracy: 0.0015 - val_loss: 6.7833e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2907e-04 - accuracy: 0.0015 - val_loss: 1.9095e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7090e-04 - accuracy: 0.0015 - val_loss: 3.8578e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9643e-04 - accuracy: 0.0015 - val_loss: 3.2163e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 6.3734e-04 - accuracy: 0.0015 - val_loss: 1.5532e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/500\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 1.6737e-04 - accuracy: 0.0015 - val_loss: 2.1431e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.0959e-04 - accuracy: 0.0015 - val_loss: 1.0843e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/500\n",
            "42/42 [==============================] - 1s 17ms/step - loss: 9.8522e-05 - accuracy: 0.0015 - val_loss: 1.0301e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 1.1420e-04 - accuracy: 0.0015 - val_loss: 1.4435e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 8.9714e-05 - accuracy: 0.0015 - val_loss: 1.0370e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 6.0450e-05 - accuracy: 0.0015 - val_loss: 1.1831e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/500\n",
            "42/42 [==============================] - 1s 14ms/step - loss: 1.0519e-04 - accuracy: 0.0015 - val_loss: 6.5714e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.7066e-05 - accuracy: 0.0015 - val_loss: 5.5051e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4456e-05 - accuracy: 0.0015 - val_loss: 5.4063e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8609e-05 - accuracy: 0.0015 - val_loss: 6.4180e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3604e-04 - accuracy: 0.0015 - val_loss: 4.0365e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7758e-04 - accuracy: 0.0015 - val_loss: 8.6275e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.6700e-05 - accuracy: 0.0015 - val_loss: 9.9214e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1555e-04 - accuracy: 0.0015 - val_loss: 6.9932e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.3155e-05 - accuracy: 0.0015 - val_loss: 8.8239e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.3033e-04 - accuracy: 0.0015 - val_loss: 4.0371e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.2650e-04 - accuracy: 0.0015 - val_loss: 9.1473e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.9893e-04 - accuracy: 0.0015 - val_loss: 3.1665e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3651e-04 - accuracy: 0.0015 - val_loss: 2.6538e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7501e-04 - accuracy: 0.0015 - val_loss: 1.0012e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1130e-04 - accuracy: 0.0015 - val_loss: 2.4969e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2753e-04 - accuracy: 0.0015 - val_loss: 3.3906e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.3955e-04 - accuracy: 0.0015 - val_loss: 3.5743e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5576e-04 - accuracy: 0.0015 - val_loss: 3.7041e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9920e-04 - accuracy: 0.0015 - val_loss: 1.7793e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1631e-04 - accuracy: 0.0015 - val_loss: 4.1303e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9054e-04 - accuracy: 0.0015 - val_loss: 1.2565e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.0739e-04 - accuracy: 0.0015 - val_loss: 2.4845e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.9850e-04 - accuracy: 0.0015 - val_loss: 1.8790e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7141e-04 - accuracy: 0.0015 - val_loss: 2.5953e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5260e-04 - accuracy: 0.0015 - val_loss: 1.2592e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1167e-04 - accuracy: 0.0015 - val_loss: 2.0266e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1196e-04 - accuracy: 0.0015 - val_loss: 2.3275e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.8453e-05 - accuracy: 0.0015 - val_loss: 9.8069e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.0985e-05 - accuracy: 0.0015 - val_loss: 9.2566e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.6795e-05 - accuracy: 0.0015 - val_loss: 1.1426e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3917e-04 - accuracy: 0.0015 - val_loss: 8.5300e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8522e-04 - accuracy: 0.0015 - val_loss: 4.6588e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.4588e-04 - accuracy: 0.0015 - val_loss: 6.4577e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.0569e-04 - accuracy: 0.0015 - val_loss: 3.1983e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.3958e-04 - accuracy: 0.0015 - val_loss: 7.0546e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5042e-04 - accuracy: 0.0015 - val_loss: 1.1899e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.0780e-05 - accuracy: 0.0015 - val_loss: 1.6896e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.2779e-04 - accuracy: 0.0015 - val_loss: 1.5575e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 7.5472e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 7.5472e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.0015 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 7.5472e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 7.5472e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 7.5472e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.0015 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 7.5472e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0015 - val_loss: 9.2004e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 6.4333e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.5325e-04 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.1131e-04 - accuracy: 0.0015 - val_loss: 5.0042e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.8459e-04 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.4700e-04 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5509e-04 - accuracy: 0.0015 - val_loss: 5.1058e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.6707e-04 - accuracy: 0.0015 - val_loss: 4.3318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.5258e-04 - accuracy: 0.0015 - val_loss: 5.3739e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.8104e-04 - accuracy: 0.0015 - val_loss: 6.3124e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.3421e-04 - accuracy: 0.0015 - val_loss: 5.0092e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6528e-04 - accuracy: 0.0015 - val_loss: 3.5371e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9813e-04 - accuracy: 0.0015 - val_loss: 1.9954e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7441e-04 - accuracy: 0.0015 - val_loss: 2.4984e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.5738e-04 - accuracy: 0.0015 - val_loss: 8.4293e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.5455e-04 - accuracy: 0.0015 - val_loss: 5.0055e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6327e-04 - accuracy: 0.0015 - val_loss: 2.0451e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4799e-04 - accuracy: 0.0015 - val_loss: 1.8573e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1361e-04 - accuracy: 0.0015 - val_loss: 1.8864e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0682e-04 - accuracy: 0.0015 - val_loss: 3.9100e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5768e-04 - accuracy: 0.0015 - val_loss: 3.1674e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.4619e-04 - accuracy: 0.0015 - val_loss: 2.4088e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 2.8900e-04 - accuracy: 0.0015 - val_loss: 4.0210e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 7.3657e-04 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 8.4739e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 5.1386e-04 - accuracy: 0.0015 - val_loss: 8.3058e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.4002e-04 - accuracy: 0.0015 - val_loss: 2.9318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 1.8786e-04 - accuracy: 0.0015 - val_loss: 4.0672e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.6606e-04 - accuracy: 0.0015 - val_loss: 2.0354e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.7347e-04 - accuracy: 0.0015 - val_loss: 2.1144e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.4886e-04 - accuracy: 0.0015 - val_loss: 1.6602e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 1.1721e-04 - accuracy: 0.0015 - val_loss: 1.1159e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 3.7588e-04 - accuracy: 0.0015 - val_loss: 4.3799e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 5.0509e-04 - accuracy: 0.0015 - val_loss: 4.2534e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 4.4591e-04 - accuracy: 0.0015 - val_loss: 5.1754e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 4.7383e-04 - accuracy: 0.0015 - val_loss: 1.6976e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1001e-04 - accuracy: 0.0015 - val_loss: 1.1564e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.3798e-05 - accuracy: 0.0015 - val_loss: 1.1977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.3079e-05 - accuracy: 0.0015 - val_loss: 1.1542e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2029e-04 - accuracy: 0.0015 - val_loss: 1.9403e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.5089e-04 - accuracy: 0.0015 - val_loss: 3.8113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7169e-04 - accuracy: 0.0015 - val_loss: 1.4650e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2265e-04 - accuracy: 0.0015 - val_loss: 8.6551e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5998e-05 - accuracy: 0.0015 - val_loss: 1.1421e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.9499e-05 - accuracy: 0.0015 - val_loss: 1.0098e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.0448e-05 - accuracy: 0.0015 - val_loss: 9.4503e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0965e-05 - accuracy: 0.0015 - val_loss: 1.2290e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.8680e-05 - accuracy: 0.0015 - val_loss: 1.5790e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.7187e-05 - accuracy: 0.0015 - val_loss: 1.4623e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2820e-04 - accuracy: 0.0015 - val_loss: 8.5395e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1741e-05 - accuracy: 0.0015 - val_loss: 8.7551e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.9560e-05 - accuracy: 0.0015 - val_loss: 1.4390e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.9896e-05 - accuracy: 0.0015 - val_loss: 1.0079e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3371e-04 - accuracy: 0.0015 - val_loss: 8.5287e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.8245e-04 - accuracy: 0.0015 - val_loss: 2.5680e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 7.0232e-04 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0444e-04 - accuracy: 0.0015 - val_loss: 4.6336e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5495e-04 - accuracy: 0.0015 - val_loss: 1.6223e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4385e-04 - accuracy: 0.0015 - val_loss: 3.5315e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3174e-04 - accuracy: 0.0015 - val_loss: 3.4310e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.6120e-04 - accuracy: 0.0015 - val_loss: 3.3052e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4212e-04 - accuracy: 0.0015 - val_loss: 1.0039e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4360e-04 - accuracy: 0.0015 - val_loss: 1.9455e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1183e-04 - accuracy: 0.0015 - val_loss: 1.0882e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.7469e-05 - accuracy: 0.0015 - val_loss: 1.2911e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1062e-05 - accuracy: 0.0015 - val_loss: 8.8141e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.2452e-05 - accuracy: 0.0015 - val_loss: 9.0727e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3019e-05 - accuracy: 0.0015 - val_loss: 7.3731e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9571e-05 - accuracy: 0.0015 - val_loss: 8.1685e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9701e-05 - accuracy: 0.0015 - val_loss: 8.2011e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4358e-04 - accuracy: 0.0015 - val_loss: 1.9523e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0381e-04 - accuracy: 0.0015 - val_loss: 2.9030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.6514e-04 - accuracy: 0.0015 - val_loss: 7.4327e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0015 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 7.5472e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "Mean Squared Error: 0.003646065498982266\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming X_train_scaled, Y_train_scaled, X_test_scaled, and Y_test_scaled are defined\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(Y_train_scaled.shape[1])  # Output layer with the same number of units as target variables\n",
        "])\n",
        "\n",
        "# Compile the model without accuracy as a metric\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, Y_train_scaled, epochs=500, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "Y_pred_scaled = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(Y_test_scaled, Y_pred_scaled)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bk6sFfEgebXD",
        "outputId": "55e9223a-b00c-4a8b-de71-61a76d72e9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "42/42 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0048\n",
            "Epoch 2/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0031\n",
            "Epoch 3/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0030\n",
            "Epoch 4/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0028\n",
            "Epoch 5/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 6/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 7/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 8/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 9/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 10/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 11/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 12/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 13/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 14/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 15/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 16/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 17/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 18/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 19/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 20/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0030\n",
            "Epoch 21/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 22/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 23/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 24/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0029\n",
            "Epoch 25/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 26/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0029\n",
            "Epoch 27/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 28/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 29/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 30/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 31/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0028\n",
            "Epoch 32/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 33/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 34/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 35/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 36/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 37/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 38/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 39/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0030\n",
            "Epoch 40/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 41/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 42/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 43/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0033\n",
            "Epoch 44/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0028\n",
            "Epoch 45/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 46/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 47/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 48/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0029\n",
            "Epoch 49/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 50/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0031\n",
            "Epoch 51/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 52/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 53/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 54/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 55/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0028\n",
            "Epoch 56/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0028\n",
            "Epoch 57/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 58/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 59/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0032\n",
            "Epoch 60/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0030\n",
            "Epoch 61/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 62/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0029\n",
            "Epoch 63/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0027\n",
            "Epoch 64/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0029\n",
            "Epoch 65/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 66/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0028\n",
            "Epoch 67/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 68/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0027\n",
            "Epoch 69/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 70/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 71/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 72/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0027\n",
            "Epoch 73/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 74/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0028\n",
            "Epoch 75/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 76/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0026\n",
            "Epoch 77/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0027\n",
            "Epoch 78/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0027\n",
            "Epoch 79/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0027\n",
            "Epoch 80/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0031\n",
            "Epoch 81/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0026\n",
            "Epoch 82/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0027\n",
            "Epoch 83/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0032\n",
            "Epoch 84/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0027\n",
            "Epoch 85/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 86/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0026\n",
            "Epoch 87/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0028\n",
            "Epoch 88/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0028\n",
            "Epoch 89/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0026\n",
            "Epoch 90/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0026\n",
            "Epoch 91/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0029\n",
            "Epoch 92/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0026\n",
            "Epoch 93/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0029\n",
            "Epoch 94/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 95/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0028\n",
            "Epoch 96/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 97/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0025\n",
            "Epoch 98/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0025\n",
            "Epoch 99/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0026\n",
            "Epoch 100/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0026\n",
            "Epoch 101/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0027\n",
            "Epoch 102/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0029\n",
            "Epoch 103/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0025\n",
            "Epoch 104/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0025\n",
            "Epoch 105/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0026\n",
            "Epoch 106/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0026\n",
            "Epoch 107/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0024\n",
            "Epoch 108/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0026\n",
            "Epoch 109/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0026\n",
            "Epoch 110/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0027\n",
            "Epoch 111/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0026\n",
            "Epoch 112/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0027\n",
            "Epoch 113/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0030\n",
            "Epoch 114/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0024\n",
            "Epoch 115/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0026\n",
            "Epoch 116/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0024\n",
            "Epoch 117/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0025\n",
            "Epoch 118/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0024\n",
            "Epoch 119/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0025\n",
            "Epoch 120/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 121/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0024\n",
            "Epoch 122/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0027\n",
            "Epoch 123/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0026\n",
            "Epoch 124/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0023\n",
            "Epoch 125/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0024\n",
            "Epoch 126/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 127/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0026\n",
            "Epoch 128/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0025\n",
            "Epoch 129/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0023\n",
            "Epoch 130/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0025\n",
            "Epoch 131/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0025\n",
            "Epoch 132/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0024\n",
            "Epoch 133/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 134/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0024\n",
            "Epoch 135/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 136/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
            "Epoch 137/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0025\n",
            "Epoch 138/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0021\n",
            "Epoch 139/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 140/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
            "Epoch 141/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0022\n",
            "Epoch 142/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 143/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 144/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 145/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 146/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 147/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 148/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 149/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 150/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 151/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 152/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 153/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0019\n",
            "Epoch 154/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 155/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 156/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 157/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 158/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 159/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 160/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 161/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 162/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 163/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 164/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 165/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 166/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 167/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 168/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 169/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 170/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 171/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 172/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 173/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 174/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 175/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 176/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 177/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 178/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 179/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 180/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 181/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 182/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 183/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 184/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 185/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 186/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 187/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 188/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 189/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 190/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 191/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 192/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.8580e-04\n",
            "Epoch 193/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.9542e-04 - val_loss: 0.0012\n",
            "Epoch 194/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0010\n",
            "Epoch 195/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 196/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 197/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.4900e-04 - val_loss: 0.0012\n",
            "Epoch 198/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.9318e-04\n",
            "Epoch 199/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.5613e-04 - val_loss: 0.0010\n",
            "Epoch 200/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.5727e-04 - val_loss: 9.9137e-04\n",
            "Epoch 201/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 202/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0012\n",
            "Epoch 203/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 9.5701e-04\n",
            "Epoch 204/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 205/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 9.2652e-04 - val_loss: 9.3314e-04\n",
            "Epoch 206/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.5544e-04 - val_loss: 0.0013\n",
            "Epoch 207/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0041\n",
            "Epoch 208/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 9.3013e-04\n",
            "Epoch 209/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.6511e-04 - val_loss: 0.0024\n",
            "Epoch 210/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 211/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 212/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 213/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 6.1873e-04\n",
            "Epoch 214/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 215/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.7307e-04 - val_loss: 0.0012\n",
            "Epoch 216/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8989e-04 - val_loss: 6.2318e-04\n",
            "Epoch 217/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 6.8538e-04 - val_loss: 0.0012\n",
            "Epoch 218/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.9294e-04 - val_loss: 5.7962e-04\n",
            "Epoch 219/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 220/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 6.2882e-04\n",
            "Epoch 221/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.9958e-04 - val_loss: 0.0011\n",
            "Epoch 222/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0040\n",
            "Epoch 223/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 9.8338e-04\n",
            "Epoch 224/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.2339e-04 - val_loss: 6.6621e-04\n",
            "Epoch 225/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 6.9571e-04 - val_loss: 8.5972e-04\n",
            "Epoch 226/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 227/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.9495e-04 - val_loss: 6.1116e-04\n",
            "Epoch 228/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.0926e-04\n",
            "Epoch 229/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.6724e-04 - val_loss: 7.2592e-04\n",
            "Epoch 230/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5751e-04 - val_loss: 0.0016\n",
            "Epoch 231/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 232/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 233/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 234/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.8993e-04\n",
            "Epoch 235/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.0993e-04\n",
            "Epoch 236/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0052\n",
            "Epoch 237/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0012\n",
            "Epoch 238/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 7.3593e-04\n",
            "Epoch 239/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 240/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 7.9329e-04 - val_loss: 4.8087e-04\n",
            "Epoch 241/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 5.3207e-04 - val_loss: 0.0014\n",
            "Epoch 242/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 5.5234e-04\n",
            "Epoch 243/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 5.8416e-04 - val_loss: 6.3975e-04\n",
            "Epoch 244/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 6.6146e-04 - val_loss: 4.3223e-04\n",
            "Epoch 245/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 8.2870e-04 - val_loss: 7.9714e-04\n",
            "Epoch 246/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.5899e-04 - val_loss: 5.2721e-04\n",
            "Epoch 247/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.3299e-04 - val_loss: 3.1343e-04\n",
            "Epoch 248/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.2755e-04 - val_loss: 3.5987e-04\n",
            "Epoch 249/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.1611e-04 - val_loss: 3.1076e-04\n",
            "Epoch 250/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.6910e-04 - val_loss: 8.7539e-04\n",
            "Epoch 251/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.2587e-04 - val_loss: 2.7262e-04\n",
            "Epoch 252/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.0682e-04 - val_loss: 0.0017\n",
            "Epoch 253/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 4.8648e-04 - val_loss: 4.0913e-04\n",
            "Epoch 254/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 4.0277e-04 - val_loss: 3.1497e-04\n",
            "Epoch 255/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5583e-04 - val_loss: 2.1933e-04\n",
            "Epoch 256/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 3.6368e-04 - val_loss: 3.5121e-04\n",
            "Epoch 257/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5047e-04 - val_loss: 3.8264e-04\n",
            "Epoch 258/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4497e-04 - val_loss: 5.2106e-04\n",
            "Epoch 259/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8736e-04 - val_loss: 4.7554e-04\n",
            "Epoch 260/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 7.1137e-04\n",
            "Epoch 261/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.7218e-04 - val_loss: 3.0800e-04\n",
            "Epoch 262/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.0348e-04 - val_loss: 2.3323e-04\n",
            "Epoch 263/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1085e-04 - val_loss: 3.8018e-04\n",
            "Epoch 264/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7428e-04 - val_loss: 1.4806e-04\n",
            "Epoch 265/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.6811e-04 - val_loss: 1.7852e-04\n",
            "Epoch 266/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5052e-04 - val_loss: 1.7077e-04\n",
            "Epoch 267/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.3628e-04 - val_loss: 4.4014e-04\n",
            "Epoch 268/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4101e-04 - val_loss: 1.3971e-04\n",
            "Epoch 269/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.6796e-04 - val_loss: 2.1181e-04\n",
            "Epoch 270/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7823e-04 - val_loss: 1.4201e-04\n",
            "Epoch 271/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6362e-04 - val_loss: 1.2418e-04\n",
            "Epoch 272/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1128e-04 - val_loss: 2.1207e-04\n",
            "Epoch 273/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1297e-04 - val_loss: 1.9447e-04\n",
            "Epoch 274/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.2379e-04 - val_loss: 5.5181e-04\n",
            "Epoch 275/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8686e-04 - val_loss: 1.2408e-04\n",
            "Epoch 276/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1424e-04 - val_loss: 2.8365e-04\n",
            "Epoch 277/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6135e-04 - val_loss: 3.7002e-04\n",
            "Epoch 278/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3458e-04 - val_loss: 1.8851e-04\n",
            "Epoch 279/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0269e-04 - val_loss: 5.2245e-04\n",
            "Epoch 280/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.9451e-04 - val_loss: 0.0013\n",
            "Epoch 281/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 282/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 7.7064e-04\n",
            "Epoch 283/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9773e-04 - val_loss: 3.9249e-04\n",
            "Epoch 284/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.6385e-04 - val_loss: 4.2792e-04\n",
            "Epoch 285/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7311e-04 - val_loss: 4.9178e-04\n",
            "Epoch 286/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.6910e-04\n",
            "Epoch 287/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8608e-04 - val_loss: 2.6438e-04\n",
            "Epoch 288/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8418e-04 - val_loss: 4.1665e-04\n",
            "Epoch 289/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.9594e-04 - val_loss: 2.0760e-04\n",
            "Epoch 290/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.9681e-04 - val_loss: 2.6379e-04\n",
            "Epoch 291/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5510e-04 - val_loss: 2.0162e-04\n",
            "Epoch 292/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7835e-04 - val_loss: 2.2920e-04\n",
            "Epoch 293/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.9299e-04 - val_loss: 3.1906e-04\n",
            "Epoch 294/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.9655e-04 - val_loss: 2.5102e-04\n",
            "Epoch 295/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8968e-04 - val_loss: 2.2085e-04\n",
            "Epoch 296/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.6119e-04 - val_loss: 2.5662e-04\n",
            "Epoch 297/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1584e-04 - val_loss: 1.8039e-04\n",
            "Epoch 298/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.0289e-04 - val_loss: 1.6321e-04\n",
            "Epoch 299/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.9532e-04 - val_loss: 1.6868e-04\n",
            "Epoch 300/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4306e-04 - val_loss: 1.7741e-04\n",
            "Epoch 301/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1978e-04 - val_loss: 1.5730e-04\n",
            "Epoch 302/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 9.6874e-05 - val_loss: 2.3011e-04\n",
            "Epoch 303/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6186e-04 - val_loss: 0.0021\n",
            "Epoch 304/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 2.9061e-04\n",
            "Epoch 305/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 2.4515e-04 - val_loss: 3.8288e-04\n",
            "Epoch 306/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4565e-04 - val_loss: 4.0453e-04\n",
            "Epoch 307/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.2326e-04 - val_loss: 5.1928e-04\n",
            "Epoch 308/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.4729e-04 - val_loss: 2.7295e-04\n",
            "Epoch 309/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2292e-04 - val_loss: 1.5388e-04\n",
            "Epoch 310/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.7806e-04 - val_loss: 1.8708e-04\n",
            "Epoch 311/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1488e-04 - val_loss: 2.1938e-04\n",
            "Epoch 312/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.3173e-04 - val_loss: 2.9306e-04\n",
            "Epoch 313/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.8498e-04 - val_loss: 2.9654e-04\n",
            "Epoch 314/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0111e-04 - val_loss: 1.5062e-04\n",
            "Epoch 315/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9034e-05 - val_loss: 1.2077e-04\n",
            "Epoch 316/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.7231e-05 - val_loss: 1.5389e-04\n",
            "Epoch 317/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.1981e-05 - val_loss: 1.1980e-04\n",
            "Epoch 318/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.2796e-05 - val_loss: 1.4647e-04\n",
            "Epoch 319/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.2556e-05 - val_loss: 1.3278e-04\n",
            "Epoch 320/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.6042e-05 - val_loss: 1.3688e-04\n",
            "Epoch 321/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.0259e-05 - val_loss: 1.6198e-04\n",
            "Epoch 322/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0100e-05 - val_loss: 1.2009e-04\n",
            "Epoch 323/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3517e-04 - val_loss: 3.8283e-04\n",
            "Epoch 324/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5896e-04 - val_loss: 1.3262e-04\n",
            "Epoch 325/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.9390e-05 - val_loss: 1.7291e-04\n",
            "Epoch 326/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0483e-04 - val_loss: 7.1493e-04\n",
            "Epoch 327/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 6.2208e-04\n",
            "Epoch 328/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0027\n",
            "Epoch 329/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 330/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0011\n",
            "Epoch 331/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 8.7839e-04\n",
            "Epoch 332/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
            "Epoch 333/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 334/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 335/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 9.8604e-04 - val_loss: 7.0480e-04\n",
            "Epoch 336/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 9.9992e-04 - val_loss: 7.1748e-04\n",
            "Epoch 337/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 8.8457e-04\n",
            "Epoch 338/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0024\n",
            "Epoch 339/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 340/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.5016e-04 - val_loss: 6.6115e-04\n",
            "Epoch 341/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 342/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 9.6299e-04\n",
            "Epoch 343/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.3572e-04\n",
            "Epoch 344/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 7.4159e-04 - val_loss: 4.6696e-04\n",
            "Epoch 345/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 6.7866e-04 - val_loss: 0.0022\n",
            "Epoch 346/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 5.8317e-04\n",
            "Epoch 347/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.2518e-04 - val_loss: 8.8305e-04\n",
            "Epoch 348/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.4131e-04 - val_loss: 9.8241e-04\n",
            "Epoch 349/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 350/500\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 5.6656e-04\n",
            "Epoch 351/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 4.8718e-04 - val_loss: 3.6554e-04\n",
            "Epoch 352/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.7636e-04 - val_loss: 3.6282e-04\n",
            "Epoch 353/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.3437e-04 - val_loss: 5.7942e-04\n",
            "Epoch 354/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.2906e-04 - val_loss: 3.6848e-04\n",
            "Epoch 355/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8550e-04 - val_loss: 3.7855e-04\n",
            "Epoch 356/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.3984e-04 - val_loss: 3.4263e-04\n",
            "Epoch 357/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.5049e-04 - val_loss: 2.9135e-04\n",
            "Epoch 358/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.9850e-04 - val_loss: 3.6398e-04\n",
            "Epoch 359/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7326e-04 - val_loss: 2.8399e-04\n",
            "Epoch 360/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.2553e-04 - val_loss: 2.0404e-04\n",
            "Epoch 361/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7378e-04 - val_loss: 2.0169e-04\n",
            "Epoch 362/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7202e-04 - val_loss: 1.7651e-04\n",
            "Epoch 363/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.3532e-04 - val_loss: 2.5354e-04\n",
            "Epoch 364/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.9971e-04 - val_loss: 2.2155e-04\n",
            "Epoch 365/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.9678e-04 - val_loss: 7.6049e-04\n",
            "Epoch 366/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.6751e-04 - val_loss: 4.1405e-04\n",
            "Epoch 367/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.6436e-04 - val_loss: 1.6433e-04\n",
            "Epoch 368/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5073e-04 - val_loss: 0.0011\n",
            "Epoch 369/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9550e-04 - val_loss: 7.1542e-04\n",
            "Epoch 370/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.0611e-04 - val_loss: 3.6455e-04\n",
            "Epoch 371/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6031e-04 - val_loss: 4.6221e-04\n",
            "Epoch 372/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.4071e-04 - val_loss: 1.8827e-04\n",
            "Epoch 373/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7994e-04 - val_loss: 1.2901e-04\n",
            "Epoch 374/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.7836e-04 - val_loss: 3.9684e-04\n",
            "Epoch 375/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.9651e-04 - val_loss: 4.9258e-04\n",
            "Epoch 376/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.5030e-04 - val_loss: 1.7579e-04\n",
            "Epoch 377/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.8259e-04 - val_loss: 3.8729e-04\n",
            "Epoch 378/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.0868e-04 - val_loss: 9.7228e-04\n",
            "Epoch 379/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0012\n",
            "Epoch 380/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 5.1138e-04\n",
            "Epoch 381/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8437e-04 - val_loss: 1.5075e-04\n",
            "Epoch 382/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.1281e-04 - val_loss: 1.7139e-04\n",
            "Epoch 383/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4358e-04 - val_loss: 1.7810e-04\n",
            "Epoch 384/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.7378e-04 - val_loss: 1.6885e-04\n",
            "Epoch 385/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5055e-04 - val_loss: 1.4528e-04\n",
            "Epoch 386/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2848e-04 - val_loss: 1.3430e-04\n",
            "Epoch 387/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1408e-04 - val_loss: 1.4304e-04\n",
            "Epoch 388/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.8382e-05 - val_loss: 1.2674e-04\n",
            "Epoch 389/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1590e-04 - val_loss: 1.7466e-04\n",
            "Epoch 390/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6184e-04 - val_loss: 1.5538e-04\n",
            "Epoch 391/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.0082e-04 - val_loss: 2.2847e-04\n",
            "Epoch 392/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3976e-04 - val_loss: 2.8953e-04\n",
            "Epoch 393/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5076e-04 - val_loss: 1.2621e-04\n",
            "Epoch 394/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0178e-04 - val_loss: 1.3590e-04\n",
            "Epoch 395/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.4461e-05 - val_loss: 1.1166e-04\n",
            "Epoch 396/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8986e-05 - val_loss: 9.2324e-05\n",
            "Epoch 397/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.7449e-05 - val_loss: 1.0992e-04\n",
            "Epoch 398/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.8816e-05 - val_loss: 1.3275e-04\n",
            "Epoch 399/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.9556e-05 - val_loss: 9.0864e-05\n",
            "Epoch 400/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.6980e-04 - val_loss: 1.4807e-04\n",
            "Epoch 401/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.7475e-05 - val_loss: 1.5856e-04\n",
            "Epoch 402/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.8563e-05 - val_loss: 1.0140e-04\n",
            "Epoch 403/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.7299e-05 - val_loss: 1.2757e-04\n",
            "Epoch 404/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.5256e-04 - val_loss: 1.4704e-04\n",
            "Epoch 405/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.7471e-05 - val_loss: 2.4450e-04\n",
            "Epoch 406/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.9927e-05 - val_loss: 1.0657e-04\n",
            "Epoch 407/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2783e-04 - val_loss: 2.4231e-04\n",
            "Epoch 408/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.4463e-04 - val_loss: 7.8528e-04\n",
            "Epoch 409/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 3.1586e-04\n",
            "Epoch 410/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 4.2142e-04\n",
            "Epoch 411/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.8763e-04 - val_loss: 3.4788e-04\n",
            "Epoch 412/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7549e-04 - val_loss: 3.0922e-04\n",
            "Epoch 413/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.8991e-04 - val_loss: 1.8437e-04\n",
            "Epoch 414/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.9149e-04 - val_loss: 1.3074e-04\n",
            "Epoch 415/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1283e-04 - val_loss: 2.5421e-04\n",
            "Epoch 416/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.6536e-05 - val_loss: 1.2787e-04\n",
            "Epoch 417/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0918e-04 - val_loss: 1.2169e-04\n",
            "Epoch 418/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2176e-04 - val_loss: 1.3094e-04\n",
            "Epoch 419/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.1484e-05 - val_loss: 1.3126e-04\n",
            "Epoch 420/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.4247e-05 - val_loss: 1.4844e-04\n",
            "Epoch 421/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.0266e-05 - val_loss: 1.4746e-04\n",
            "Epoch 422/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 5.0609e-05 - val_loss: 1.8790e-04\n",
            "Epoch 423/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 3.3820e-05 - val_loss: 1.0367e-04\n",
            "Epoch 424/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 6.9314e-05 - val_loss: 1.0800e-04\n",
            "Epoch 425/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1433e-04 - val_loss: 9.4100e-05\n",
            "Epoch 426/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.8916e-05 - val_loss: 1.3177e-04\n",
            "Epoch 427/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 1.5004e-04 - val_loss: 1.8886e-04\n",
            "Epoch 428/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 4.7184e-05 - val_loss: 1.5037e-04\n",
            "Epoch 429/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 4.8484e-05 - val_loss: 1.9953e-04\n",
            "Epoch 430/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.7205e-05 - val_loss: 1.1527e-04\n",
            "Epoch 431/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 3.2800e-05 - val_loss: 9.2314e-05\n",
            "Epoch 432/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 3.0729e-05 - val_loss: 1.0148e-04\n",
            "Epoch 433/500\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 2.6606e-05 - val_loss: 1.2911e-04\n",
            "Epoch 434/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.6340e-05 - val_loss: 9.6185e-05\n",
            "Epoch 435/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.9451e-05 - val_loss: 8.2060e-05\n",
            "Epoch 436/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 3.6584e-05 - val_loss: 8.1773e-05\n",
            "Epoch 437/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0381e-04 - val_loss: 3.7858e-04\n",
            "Epoch 438/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1640e-04 - val_loss: 3.3648e-04\n",
            "Epoch 439/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 440/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0030\n",
            "Epoch 441/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0027\n",
            "Epoch 442/500\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0022\n",
            "Epoch 443/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0021\n",
            "Epoch 444/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0020\n",
            "Epoch 445/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0027\n",
            "Epoch 446/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0021\n",
            "Epoch 447/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0020\n",
            "Epoch 448/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 449/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 450/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0019\n",
            "Epoch 451/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0017\n",
            "Epoch 452/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 453/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 454/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 455/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 456/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 457/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 458/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 459/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 460/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 461/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 462/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 463/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0010\n",
            "Epoch 464/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 9.4257e-04\n",
            "Epoch 465/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 9.7868e-04\n",
            "Epoch 466/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 9.3977e-04\n",
            "Epoch 467/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.7685e-04 - val_loss: 0.0018\n",
            "Epoch 468/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 469/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 9.0500e-04\n",
            "Epoch 470/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.2684e-04\n",
            "Epoch 471/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.1153e-04 - val_loss: 6.0767e-04\n",
            "Epoch 472/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 6.0338e-04\n",
            "Epoch 473/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 9.7298e-04 - val_loss: 0.0015\n",
            "Epoch 474/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 8.2529e-04 - val_loss: 4.4813e-04\n",
            "Epoch 475/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.9228e-04 - val_loss: 4.9257e-04\n",
            "Epoch 476/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.3846e-04 - val_loss: 5.1981e-04\n",
            "Epoch 477/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 7.2545e-04 - val_loss: 5.3356e-04\n",
            "Epoch 478/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.9757e-04 - val_loss: 3.2228e-04\n",
            "Epoch 479/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.8197e-04 - val_loss: 4.1373e-04\n",
            "Epoch 480/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.9298e-04 - val_loss: 3.2097e-04\n",
            "Epoch 481/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 4.2848e-04 - val_loss: 4.6630e-04\n",
            "Epoch 482/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8631e-04 - val_loss: 4.0609e-04\n",
            "Epoch 483/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.7499e-04 - val_loss: 2.1171e-04\n",
            "Epoch 484/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6772e-04 - val_loss: 4.2311e-04\n",
            "Epoch 485/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6611e-04 - val_loss: 1.9075e-04\n",
            "Epoch 486/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.5423e-04 - val_loss: 2.0370e-04\n",
            "Epoch 487/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.3740e-04 - val_loss: 2.6454e-04\n",
            "Epoch 488/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.5929e-04 - val_loss: 2.2847e-04\n",
            "Epoch 489/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.8742e-04 - val_loss: 2.7663e-04\n",
            "Epoch 490/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 3.6580e-04 - val_loss: 3.4654e-04\n",
            "Epoch 491/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.4792e-04 - val_loss: 6.5076e-04\n",
            "Epoch 492/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 5.1553e-04 - val_loss: 4.4605e-04\n",
            "Epoch 493/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 494/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 9.9481e-04\n",
            "Epoch 495/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 6.4661e-04 - val_loss: 2.4630e-04\n",
            "Epoch 496/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 2.2112e-04 - val_loss: 1.7765e-04\n",
            "Epoch 497/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.7977e-04 - val_loss: 1.3386e-04\n",
            "Epoch 498/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.5862e-04 - val_loss: 9.0140e-05\n",
            "Epoch 499/500\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.4194e-04 - val_loss: 1.2151e-04\n",
            "Epoch 500/500\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 1.3070e-04 - val_loss: 1.2411e-04\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "Mean Squared Error: 9.794620341024122e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}